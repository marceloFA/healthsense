{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MaoKznvegU8o",
    "outputId": "87d7eca9-6769-45bb-f43f-0f7c76ae5438"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (0.10.1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from joblib import dump, load\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "# old classification metrics\n",
    "from sklearn.metrics import ( classification_report, confusion_matrix, \n",
    "                             precision_score, accuracy_score, \n",
    "                             precision_recall_fscore_support )\n",
    "# new classification metrics\n",
    "from sklearn.metrics import make_scorer, roc_curve \n",
    "\n",
    "# Decision tree visualization\n",
    "!pip install graphviz\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "4NKy3F3ShyrJ",
    "outputId": "55ef3322-f426-455a-f49d-4c7a56787da9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive, files\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "v-dwa6SQkuwv",
    "outputId": "9631b33d-064d-4ee9-eb0b-de305135e005"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/UFPA/Healthsense\n"
     ]
    }
   ],
   "source": [
    "cd \"/content/drive/My Drive/UFPA/Healthsense/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ho5ZooPYgU80"
   },
   "source": [
    "## Introduzindo os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DDP33eJUgU81"
   },
   "outputs": [],
   "source": [
    "step_1 = pd.read_csv('challenge_raw_everyone.csv')\n",
    "#step_2 = pd.read_csv('challenge_processed_everyone.csv')\n",
    "#step_3 = pd.read_csv('challenge_cleaned_everyone.csv')\n",
    "#step_4 = pd.read_csv('challenge_cleaned_everyone.csv')\n",
    "#step_5 = pd.read_csv('challenge_cleaned_everyone.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zzOhh5EhlWUk"
   },
   "source": [
    "## Custom scorer based on the False Acceptance Rate and False Rejection Rate\n",
    "\n",
    "False Acceptance rate:\n",
    "\n",
    "Number acceptance of impostors / total number of impostors\n",
    "\n",
    "False Rejection rate:\n",
    "\n",
    "Number rejected of impostors / total number of impostors\n",
    "\n",
    "\n",
    "### Source of information:\n",
    "### https://www.recogtech.com/en/knowledge-base/security-level-versus-user-convenience \n",
    "### https://stackoverflow.com/questions/28339746/equal-error-rate-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aypT9VZqlVPK"
   },
   "outputs": [],
   "source": [
    "def binary_error_rate(y, y_pred, **kwargs):\n",
    "    ''' Calculates the equal error rate based on \n",
    "        False Aceptance Rate (FAR) and False Rejection Rate (FRR)\n",
    "        for a binary classification problem\n",
    "    '''\n",
    "    fpr, tpr, threshold = roc_curve(y, y_pred)\n",
    "    fnr = 1 - tpr\n",
    "    eer_threshold = threshold(np.nanargmin(np.absolute((fnr - fpr))))\n",
    "    err_rate = fpr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "    return err_rate\n",
    "\n",
    "binary_equal_error_rate = make_scorer(binary_error_rate)\n",
    "\n",
    "\n",
    "def error_rate(y, y_pred, **kwargs):\n",
    "    ''' Calculates the equal error rate based on \n",
    "        False Aceptance Rate (FAR) and False Rejection Rate (FRR)\n",
    "        for a multiclass classification problem\n",
    "    '''\n",
    "    cm = confusion_matrix(y, y_pred)    \n",
    "    fp = cm.sum(axis=0) - np.diag(cm)  \n",
    "    fn = cm.sum(axis=1) - np.diag(cm)\n",
    "    tp = np.diag(cm)\n",
    "    tn = cm.sum() - (fp + fn + tp)\n",
    "\n",
    "    # Fall out or false positive rate\n",
    "    fpr = fp/(fp+tn)\n",
    "    # False negative rate\n",
    "    fnr = fn/(tp+fn)\n",
    "\n",
    "    # old Error rate calculation\n",
    "    #err_rate = fpr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "\n",
    "    # new error rate calculation\n",
    "    err_rate = np.mean(np.absolute((fnr - fpr)))\n",
    "    print('fpr: ',fpr)\n",
    "    print('fnr: ',fnr)\n",
    "    print('error rate: ', err_rate)\n",
    "    return err_rate\n",
    "\n",
    "equal_error_rate = make_scorer(error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gtsuyT6IgU89"
   },
   "source": [
    "## Passo 1: Treino sem modificações aos dados originais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "colab_type": "code",
    "id": "YcbewVamgU9C",
    "outputId": "fbfed9d4-65b9-4865-f5a3-ac3316378785"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f87886aa3c8>"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Cumulative distribution of number of examples\")\n",
    "step_1['person'].value_counts(ascending=True).hist(cumulative=True, density=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IaSaauikmso9"
   },
   "outputs": [],
   "source": [
    "## Remove pessoas que tem menos que 28 segmentos\n",
    "min_n_of_segments = 19\n",
    "mask = step_1['person'].value_counts() < min_n_of_segments\n",
    "people_to_remove = list(mask[mask].index)\n",
    "\n",
    "for person in people_to_remove:\n",
    "    step_1 = step_1[step_1.person != person]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IXMf70cAgU8-"
   },
   "outputs": [],
   "source": [
    "original_columns = ['mean_q', 'mean_r', 'mean_s', 'stdev_q', 'stdev_r','stdev_s',\n",
    "                   'mean_rr_interval', 'mean_rq_amplitude', 'mean_qrs_interval']\n",
    "\n",
    "X_step_1 = step_1[original_columns]\n",
    "# Preenche os dados faltosos com a média da respectiva coluna\n",
    "X_step_1 = X_step_1.apply(lambda x: x.fillna(x.mean()))\n",
    "# O objeto da predição é 'y' (os rótulos das classes)\n",
    "y_step_1 = step_1['person']\n",
    "X_train_step_1, X_test_step_1, y_train_step_1, y_test_step_1 = train_test_split(X_step_1, y_step_1,\n",
    "                                                                                test_size=0.2, stratify=y_step_1,\n",
    "                                                                                random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V9sLE6uDX5e7"
   },
   "source": [
    "### New training scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 593
    },
    "colab_type": "code",
    "id": "_QiOTshxVC5y",
    "outputId": "7b2e2c2c-a69e-4581-975e-570502d81cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n",
      "[CV] max_depth=100, min_samples_leaf=5, min_samples_split=12, n_estimators=150 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fpr:  [0.         0.00053028 0.00031813 ... 0.00053028 0.00031817 0.00042427]\n",
      "fnr:  [0.2  0.4  0.25 ... 1.   0.4  0.5 ]\n",
      "error rate:  0.3514085719437247\n",
      "[CV]  max_depth=100, min_samples_leaf=5, min_samples_split=12, n_estimators=150, score=0.351, total= 1.9min\n",
      "[CV] max_depth=100, min_samples_leaf=5, min_samples_split=12, n_estimators=150 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.9min remaining:    0.0s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-c4af1cf3a593>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m                                   cv=cv, verbose=3)\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mgrid_search_step_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_step_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_step_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Best parameters were: '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrid_search_step_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_parameters_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    381\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[0;32m--> 383\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# original param grid, used the first time we trained\n",
    "param_grid = {\n",
    "    'max_depth': [100, 90, 80],\n",
    "    'min_samples_leaf': [5, 4, 3],\n",
    "    'min_samples_split': [12, 10, 8],\n",
    "    'n_estimators': [150, 125, 100]\n",
    "    }\n",
    "\n",
    "\n",
    "# Do a training scheme using grid search and cross validation\n",
    "rf_step_1 = RandomForestClassifier(n_jobs=-1)\n",
    "cv_step_1 = StratifiedKFold(n_splits=3)\n",
    "grid_search_step_1 = GridSearchCV(estimator=rf_step_1,\n",
    "                                  param_grid=param_grid,\n",
    "                                  scoring=equal_error_rate,\n",
    "                                  cv=cv_step_1, verbose=3)\n",
    "\n",
    "grid_search_step_1.fit(X_train_step_1, y_train_step_1)\n",
    "print('Best parameters were: ',grid_search_step_1.best_parameters_)\n",
    "\n",
    "# test\n",
    "predictions_step_1 = grid_search_step_1.best_estimator_.predict(X_test_step_1)\n",
    "\n",
    "\n",
    "#rfc = RandomForestClassifier(n_estimators=150, max_depth=100, min_samples_leaf=5, min_samples_split=12)\n",
    "#rfc.fit(X_train_step_1, y_train_step_1)\n",
    "#predictions_step_1 = rfc.predict(X_test_step_1)\n",
    "\n",
    "# save classification metrics\n",
    "cm = confusion_matrix(y_test_step_1, predictions_step_1)\n",
    "cr = classification_report(y_test_step_1, predictions_step_1, output_dict=True)\n",
    "\n",
    "cr_df = pd.DataFrame(cr).transpose()\n",
    "cr_df.to_csv('classification_report_1.csv')\n",
    "\n",
    "cm_df = pd.DataFrame(cm)\n",
    "cm_df.to_csv('confusion_matrx_1.csv')\n",
    "\n",
    "# Save model for future usage\n",
    "dump(clf, 'grid_search_step_1.best_estimator_.joblib')\n",
    "# if you want to laod the model:\n",
    "# rfc = load('grid_search_step_1.best_estimator_.joblib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DVDMF1CjX_EQ"
   },
   "source": [
    "## Old training scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zEft1Z_EgU9G"
   },
   "outputs": [],
   "source": [
    "# list_of_training_x = np.array_split(X_train_step_1, 2)\n",
    "# list_of_training_y = np.array_split(y_train_step_1, 2)\n",
    "# n_estimators = 5\n",
    "\n",
    "# # train in batchs\n",
    "# rf_step_1 = RandomForestClassifier(warm_start=True, n_estimators=n_estimators, max_depth=100, min_samples_leaf=3, min_samples_split=10, verbose=3)\n",
    "# for i in range(2):\n",
    "#     rf_step_1.fit(list_of_training_x[i], list_of_training_y[i])\n",
    "#     rf_step_1.set_params(n_estimators=n_estimators)\n",
    "#     n_estimators+=5\n",
    "\n",
    "# # test and save results\n",
    "# predictions_step_1 = rf_step_1.predict(X_test_step_1)\n",
    "# cr = classification_report(y_test_step_1, predictions_step_1, output_dict=True)\n",
    "# df = pd.DataFrame(cr).transpose()\n",
    "# df.to_csv('result_1.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BiUDNVKDgU9S"
   },
   "source": [
    "## Passo 2: Treino com adição de segmentos gerados aleatoriamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tF90RhgAgU9W"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Cumulative distribution of number of examples\")\n",
    "step_2['person'].value_counts(ascending=True).hist(cumulative=True, density=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "atiYKJ-mgU9T"
   },
   "outputs": [],
   "source": [
    "#le_step_2 = LabelEncoder()\n",
    "#step_2['person'] = pd.Series(le_step_2.fit_transform(step_2['person']))\n",
    "original_columns = ['mean_q', 'mean_r', 'mean_s', 'stdev_q', 'stdev_r','stdev_s',\n",
    "                   'mean_rr_interval', 'mean_rq_amplitude', 'mean_qrs_interval']\n",
    "\n",
    "X_step_2 = step_2[original_columns]\n",
    "# Preenche os dados faltosos com a média da respectiva coluna\n",
    "X_step_2 = X_step_2.apply(lambda x: x.fillna(x.mean()))\n",
    "# O objeto da predição é 'y' (os rótulos das classes)\n",
    "y_step_2 = step_2['person']\n",
    "\n",
    "X_train_step_2, X_test_step_2, y_train_step_2, y_test_step_2 = train_test_split(X_step_2, y_step_2,\n",
    "                                                                                test_size = 0.2, random_state=42\n",
    "                                                                               stratify=y_step_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SNq_lb58rpI7"
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [100, 90, 80],\n",
    "    'min_samples_leaf': [5, 4, 3],\n",
    "    'min_samples_split': [12, 10, 8],\n",
    "    'n_estimators': [150, 125, 100]\n",
    "    }\n",
    "\n",
    "\n",
    "# Do a training scheme using grid search and cross validation\n",
    "rf_step_2 = RandomForestClassifier(n_jobs=-1)\n",
    "cv_step_2 = StratifiedKFold(n_splits=3)\n",
    "grid_search_step_2 = GridSearchCV(estimator=rf_step_2,\n",
    "                                  param_grid=param_grid,\n",
    "                                  scoring=equal_error_rate,\n",
    "                                  cv=cv_step_2, verbose=3)\n",
    "\n",
    "grid_search_step_2.fit(X_train_step_2, y_train_step_2)\n",
    "print('Best parameters were: ',grid_search_step_2.best_parameters_)\n",
    "\n",
    "# test\n",
    "predictions_step_2 = grid_search_step_2.best_estimator_.predict(X_test_step_2)\n",
    "\n",
    "\n",
    "#rfc = RandomForestClassifier(n_estimators=150, max_depth=100, min_samples_leaf=5, min_samples_split=12)\n",
    "#rfc.fit(X_train_step_2, y_train_step_2)\n",
    "#predictions_step_2 = rfc.predict(X_test_step_2)\n",
    "\n",
    "# save classification metrics\n",
    "cm_step_2 = confusion_matrix(y_test_step_2, predictions_step_2)\n",
    "cr_step_2 = classification_report(y_test_step_2, predictions_step_2, output_dict=True)\n",
    "\n",
    "cr_df = pd.DataFrame(cr).transpose()\n",
    "cr_df.to_csv('classification_report_2.csv')\n",
    "\n",
    "pd.DataFrame(cm_step_2).to_csv('confusion_matrx_2.csv')\n",
    "\n",
    "# Save model for future usage\n",
    "dump(clf, 'grid_search_step_2.best_estimator_.joblib')\n",
    "# if you want to laod the model:\n",
    "# rfc = load('grid_search_step_2.best_estimator_.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wE1AKp_yren7"
   },
   "source": [
    "## Old training scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z8BfbMQhgU9a"
   },
   "outputs": [],
   "source": [
    "# list_of_training_x = np.array_split(X_train_step_2, 2)\n",
    "# list_of_training_y = np.array_split(y_train_step_2, 2)\n",
    "# n_estimators = 50\n",
    "\n",
    "# rf_step_2 = RandomForestClassifier(warm_start=True, n_estimators=n_estimators, max_depth=100, min_samples_leaf=3, min_samples_split=10, verbose=3)\n",
    "# for i in range(2):\n",
    "#     rf_step_2.fit(list_of_training_x[i], list_of_training_y[i])\n",
    "#     rf_step_2.set_params(n_estimators=n_estimators)\n",
    "#     n_estimators+=50\n",
    "\n",
    "# predictions_step_2 = rf_step_2.predict(X_test_step_2)\n",
    "\n",
    "\n",
    "# # testing\n",
    "# cr_step_2 = classification_report(y_test_step_2, predictions_step_2, output_dict=True)\n",
    "# cr_df_step_2 = pd.DataFrame(cr_step_2).transpose()\n",
    "# cr_df_step_2.to_csv('result_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1_9qq_BNgU9g"
   },
   "source": [
    "## Passo 3: Treino com adição de segmentos gerados aleatoriamente e remoção de outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o3Sfs4nbhrIY"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Cumulative distribution of number of examples\")\n",
    "step_3['person'].value_counts(ascending=True).hist(cumulative=True, density=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WLj6E66ChyN_"
   },
   "outputs": [],
   "source": [
    "## Remove pessoas que tem menos que 60 segmentos\n",
    "min_n_of_segments = 60\n",
    "mask = step_3['person'].value_counts() < min_n_of_segments\n",
    "people_to_remove = list(mask[mask].index)\n",
    "for person in people_to_remove:\n",
    "    step_3 = step_3[step_3.person != person]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gE95-EKZRUAs"
   },
   "outputs": [],
   "source": [
    "#le_step_3 = LabelEncoder()\n",
    "#step_3['person'] = pd.Series(le_step_3.fit_transform(step_3['person']))\n",
    "original_columns = ['mean_q', 'mean_r', 'mean_s', 'stdev_q', 'stdev_r','stdev_s',\n",
    "                   'mean_rr_interval', 'mean_rq_amplitude', 'mean_qrs_interval']\n",
    "\n",
    "X_step_3 = step_3[original_columns]\n",
    "# Preenche os dados faltosos com a média da respectiva coluna\n",
    "X_step_3 = X_step_3.apply(lambda x: x.fillna(x.mean()))\n",
    "# O objeto da predição é 'y' (os rótulos das classes)\n",
    "y_step_3 = step_3['person']\n",
    "\n",
    "X_train_step_3, X_test_step_3, y_train_step_3, y_test_step_3 = train_test_split(X_step_3, y_step_3,\n",
    "                                                                                test_size = 0.2, random_state=42,\n",
    "                                                                                stratify=y_step_3)\n",
    "print(f'Há {y_train_step_3.nunique()} classes únicas no conjunto de TREINO')\n",
    "print(f'Há {y_test_step_3.nunique()} classes únicas no conjunto de TESTE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4TzRtRSRsPz1"
   },
   "outputs": [],
   "source": [
    "# original param grid, used the first time we trained\n",
    "param_grid = {\n",
    "    'max_depth': [100, 90, 80],\n",
    "    'min_samples_leaf': [5, 4, 3],\n",
    "    'min_samples_split': [12, 10, 8],\n",
    "    'n_estimators': [150, 125, 100]\n",
    "    }\n",
    "\n",
    "\n",
    "# Do a training scheme using grid search and cross validation\n",
    "rf_step_3 = RandomForestClassifier(n_jobs=-1)\n",
    "cv_step_3 = StratifiedKFold(n_splits=3)\n",
    "grid_search_step_3 = GridSearchCV(estimator=rf_step_3,\n",
    "                                  param_grid=param_grid,\n",
    "                                  scoring=equal_error_rate,\n",
    "                                  cv=cv_step_3, verbose=3)\n",
    "\n",
    "grid_search_step_3.fit(X_train_step_3, y_train_step_3)\n",
    "print('Best parameters were: ',grid_search_step_3.best_parameters_)\n",
    "\n",
    "# test\n",
    "predictions_step_3 = grid_search_step_3.best_estimator_.predict(X_test_step_3)\n",
    "\n",
    "\n",
    "#rfc = RandomForestClassifier(n_estimators=150, max_depth=100, min_samples_leaf=5, min_samples_split=12)\n",
    "#rfc.fit(X_train_step_3, y_train_step_3)\n",
    "#predictions_step_3 = rfc.predict(X_test_step_3)\n",
    "\n",
    "# save classification metrics\n",
    "cm_step_3 = confusion_matrix(y_test_step_3, predictions_step_3)\n",
    "cr_step_3 = classification_report(y_test_step_3, predictions_step_3, output_dict=True)\n",
    "\n",
    "cr_df = pd.DataFrame(cr).transpose()\n",
    "cr_df.to_csv('classification_report_3.csv')\n",
    "\n",
    "pd.DataFrame(cm_step_3).to_csv('confusion_matrx_3.csv')\n",
    "\n",
    "# Save model for future usage\n",
    "dump(clf, 'grid_search_step_3.best_estimator_.joblib')\n",
    "# if you want to laod the model:\n",
    "# rfc = load('grid_search_step_3.best_estimator_.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8uvGM9J6sQm-"
   },
   "source": [
    "## Old training scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j7hC7qujReaT"
   },
   "outputs": [],
   "source": [
    "# batch_size = 3\n",
    "# list_of_training_x_step_3 = np.array_split(X_train_step_3, batch_size)\n",
    "# list_of_training_y_step_3 = np.array_split(y_train_step_3, batch_size)\n",
    "# n_estimators = 50\n",
    "\n",
    "# # Verifica sem algum split ficou com uma amostra a menos\n",
    "# for count, y in enumerate(list_of_training_y_step_3):\n",
    "#     print(f'Elementos unicos no split {count}:', y.nunique())\n",
    "\n",
    "# rf_step_3 = RandomForestClassifier(warm_start=True, n_estimators=n_estimators, max_depth=100, min_samples_leaf=3, min_samples_split=10, verbose=3)\n",
    "\n",
    "# for i in range(batch_size):\n",
    "#     rf_step_3.fit(list_of_training_x_step_3[i], list_of_training_y_step_3[i])\n",
    "#     n_estimators += 50\n",
    "#     rf_step_3.set_params(n_estimators=n_estimators)\n",
    "\n",
    "# # Testing\n",
    "# predictions_step_3 = rf_step_3.predict(X_test_step_3)\n",
    "# cr_step_3 = classification_report(y_test_step_3, predictions_step_3, output_dict=True)\n",
    "# cr_df_step_3 = pd.DataFrame(cr_step_3).transpose()\n",
    "# cr_df_step_3.to_csv('result_3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qxZFNJw802cA"
   },
   "source": [
    "## Passo 4: Todas as features, segmentos aleatórios e remoção de outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EQ1nx_pT0-A-"
   },
   "outputs": [],
   "source": [
    "## Remove pessoas que tem menos que 60 segmentos\n",
    "min_n_of_segments = 60\n",
    "mask = step_5['person'].value_counts() < min_n_of_segments\n",
    "people_to_remove = list(mask[mask].index)\n",
    "\n",
    "for person in people_to_remove:\n",
    "    step_4 = step_5[step_5.person != person]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZRVbP5r01Lsz"
   },
   "outputs": [],
   "source": [
    "#le_step_4 = LabelEncoder()\n",
    "#step_5['person'] = pd.Series(le_step_4.fit_transform(step_5['person']))\n",
    "\n",
    "X_step_4 = step_5.drop('person', axis=1)\n",
    "# Preenche os dados faltosos com a média da respectiva coluna\n",
    "X_step_4 = X_step_4.apply(lambda x: x.fillna(x.mean()))\n",
    "# O objeto da predição é 'y' (os rótulos das classes)\n",
    "y_step_4 = step_5['person']\n",
    "\n",
    "X_train_step_4, X_test_step_4, y_train_step_4, y_test_step_4 = train_test_split(X_step_4, y_step_4,\n",
    "                                                                                test_size = 0.2, random_state=42\n",
    "                                                                                stratify=y_step_4)\n",
    "print(f'Há {y_train_step_4.nunique()} classes únicas no conjunto de TREINO')\n",
    "print(f'Há {y_test_step_4.nunique()} classes únicas no conjunto de TESTE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BmyfE_dVs8eK"
   },
   "outputs": [],
   "source": [
    "# original param grid, used the first time we trained\n",
    "param_grid = {\n",
    "    'max_depth': [100, 90, 80],\n",
    "    'min_samples_leaf': [5, 4, 3],\n",
    "    'min_samples_split': [12, 10, 8],\n",
    "    'n_estimators': [150, 125, 100]\n",
    "    }\n",
    "\n",
    "\n",
    "# Do a training scheme using grid search and cross validation\n",
    "rf_step_4 = RandomForestClassifier(n_jobs=-1)\n",
    "cv_step_4 = StratifiedKFold(n_splits=3)\n",
    "grid_search_step_4 = GridSearchCV(estimator=rf_step_4,\n",
    "                                  param_grid=param_grid,\n",
    "                                  scoring=equal_error_rate,\n",
    "                                  cv=cv_step_4, verbose=3)\n",
    "\n",
    "grid_search_step_4.fit(X_train_step_4, y_train_step_4)\n",
    "print('Best parameters were: ',grid_search_step_4.best_parameters_)\n",
    "\n",
    "# test\n",
    "predictions_step_4 = grid_search_step_4.best_estimator_.predict(X_test_step_4)\n",
    "\n",
    "\n",
    "#rfc = RandomForestClassifier(n_estimators=150, max_depth=100, min_samples_leaf=5, min_samples_split=12)\n",
    "#rfc.fit(X_train_step_4, y_train_step_4)\n",
    "#predictions_step_4 = rfc.predict(X_test_step_4)\n",
    "\n",
    "# save classification metrics\n",
    "cm_step_4 = confusion_matrix(y_test_step_4, predictions_step_4)\n",
    "cr_step_4 = classification_report(y_test_step_4, predictions_step_4, output_dict=True)\n",
    "\n",
    "cr_df = pd.DataFrame(cr).transpose()\n",
    "cr_df.to_csv('classification_report_4.csv')\n",
    "\n",
    "pd.DataFrame(cm_step_4).to_csv('confusion_matrx_4.csv')\n",
    "\n",
    "# Save model for future usage\n",
    "dump(clf, 'grid_search_step_4.best_estimator_.joblib')\n",
    "# if you want to laod the model:\n",
    "# rfc = load('grid_search_step_4.best_estimator_.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wTeUeNXAtdf1"
   },
   "source": [
    "## Old training scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3dzqPuMx1MDE"
   },
   "outputs": [],
   "source": [
    "# batch_size = 4\n",
    "# list_of_training_x_step_4 = np.array_split(X_train_step_4, batch_size)\n",
    "# list_of_training_y_step_4 = np.array_split(y_train_step_4, batch_size)\n",
    "# n_estimators = 10\n",
    "\n",
    "# # Verifica sem algum split ficou com uma amostra a menos\n",
    "# for count, y in enumerate(list_of_training_y_step_4):\n",
    "#     print(f'Elementos unicos no split {count}:', y.nunique())\n",
    "\n",
    "# rf_step_4 = RandomForestClassifier(warm_start=True, n_estimators=n_estimators, max_depth=100, min_samples_leaf=3, min_samples_split=10, verbose=3)\n",
    "\n",
    "# for i in range(batch_size):\n",
    "#     rf_step_4.fit(list_of_training_x_step_4[i], list_of_training_y_step_4[i])\n",
    "#     n_estimators += 35\n",
    "#     rf_step_4.set_params(n_estimators=n_estimators)\n",
    "\n",
    "# # Testing\n",
    "# predictions_step_4 = rf_step_4.predict(X_test_step_4)\n",
    "# cr_Step_4 = classification_report(y_test_Step_4, predictions_Step_4, output_dict=True)\n",
    "# cr_df_Step_4 = pd.DataFrame(cr_Step_4).transpose()\n",
    "# cr_df_Step_4.to_csv('result_5.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7ADmpqTQAm9M"
   },
   "source": [
    "## Visualizing a few model insights:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JAuprHe1NslJ"
   },
   "source": [
    "## Single decision tree  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JRzm9j2rNncO"
   },
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(rf_step_4.estimators_[4], out_file=None,\n",
    "                                feature_names=X_step_4.columns, max_depth=1,\n",
    "                                class_names=y.unique(),  \n",
    "                                filled=True, special_characters=True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "image_bytes = graph.pipe(format='eps')\n",
    "\n",
    "# Save tree image on Google Drive\n",
    "with open('trees_visualization.eps','wb') as picture_file:\n",
    "    picture_file.write(image_bytes)\n",
    "\n",
    "# Preview tree image o Colab\n",
    "graph.render(\"trees_visualization\") \n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xn5T0FDorrX6"
   },
   "source": [
    "## Checking model feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tq6AkhALrnKx"
   },
   "outputs": [],
   "source": [
    "importances = [(feature, round(importance, 2)) for feature, importance in zip(X_step_4.columns, rf_step_4.feature_importances_)]\n",
    "sorted_importances = sorted(importances, key=lambda x:x[1], reverse=True) \n",
    "\n",
    "for pair in sorted_importances:\n",
    "    print('Feature: {:20} Importance: {}'.format(*pair))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uP2b7Buwrz93"
   },
   "outputs": [],
   "source": [
    "x_values = range(len(rf_step_4.feature_importances_))\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.ylabel('Importance')\n",
    "plt.xlabel('Feature')\n",
    "plt.title('Feature Importance')\n",
    "plt.xticks(x_values, X_step_4.columns, rotation='vertical')\n",
    "plt.bar(x_values, rf_step_4.feature_importances_, orientation = 'vertical')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "ECG indentification scenarios.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
